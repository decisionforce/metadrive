.. _getting_start:

#############################
Getting Start with MetaDrive
#############################

Tryout MetaDrive with one line
###############################

We provide a script to let you try out MetaDrive by keyboard immediately after installation! Please run::

    # Make sure current folder does not have a sub-folder named metadrive
    python -m metadrive.examples.drive_in_single_agent_env

In the same script, you can even experience an "auto-drive" journey carried out by our pre-trained RL agent. Press T in the main window will kick-off this. You can also press H to visit the helper information on other shortcuts.


To enjoy the process of generating map through our Procedural Generation (PG) algorithm, please run this script::

    python -m metadrive.examples.procedural_generation


You can also draw multiple maps generated by PG in the top-down view via running::

    python -m metadrive.examples.draw_maps


Besides, you can verify the efficiency of MetaDrive via running::

    python -m metadrive.examples.profile_metadrive


As we will discuss in :ref:`rl_environments`, MetaDrive provides three sets of RL environments: the generalization environments, the Safe RL environments and the Multi-agent RL environments.
We provide the examples for those suites as follow:

.. code-block::

    # Make sure current folder does not have a sub-folder named metadrive

    # ===== Generalization Environments =====
    python -m metadrive.examples.drive_in_single_agent_env

    # ===== Safe RL Environments =====
    python -m metadrive.examples.drive_in_safe_metadrive_env

    # ===== Multi-agent Environments =====
    # Options for --env: roundabout, intersection, tollgate, bottleneck, parkinglot, pgma
    python -m metadrive.examples.drive_in_multi_agent_env --env pgma



Using MetaDrive in Your Code
#############################

The usage of MetaDrive is as same as other **gym** environments.
Almost all decision making algorithms are compatible with MetaDrive, as long as they are compatible with OpenAI gym.
The following scripts is a minimal example for instantiating a MetaDrive environment instance

.. code-block:: python

    import metadrive  # Import this package to register the environment!
    import gym

    env = gym.make("MetaDrive-v0", config=dict(use_render=True))
    env.reset()
    for i in range(1000):
        obs, reward, done, info = env.step(env.action_space.sample())
        env.render()
        if done:
            env.reset()
    env.close()


.. Note:: Please note that each process should only have one single MetaDrive instance due to the limit of the underlying simulation engine. As a workaround, we provide an asynchronous version of MetaDrive through `Ray framework <https://github.com/ray-project/ray>`_, please find the environment in `remove_env.py <https://github.com/decisionforce/metadrive/blob/main/metadrive/envs/remoe_env.py>`_.


Out-of-the-box Environments
#############################


.. warning:: This section is under construction!

Besides, we provide several predefined environments for different purposes shown in the following table.
Please feel free to open an issue if you want to request new environments.

+-------------------------+-------------------+----------------+---------------------------------------------------------+
| Gym Environment Name    | Random Seed Range | Number of Maps | Comments                                                |
+=========================+===================+================+=========================================================+
| `MetaDrive-test-v0`       | [0, 200)          | 200            | Test set, not change for all experiments.               |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-validation-v0` | [200, 1000)       | 800            | Validation set.                                         |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-v0`            | [1000, 1100)      | 100            | Default training setting, for quick start.              |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-10envs-v0`     | [1000, 1100)      | 10             | Training environment with 10 maps.                      |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-1000envs-v0`   | [1000, 1100)      | 1000           | Training environment with 1000 maps.                    |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-training0-v0`  | [3000, 4000)      | 1000           | First set of 1000 environments.                         |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-training1-v0`  | [5000, 6000)      | 1000           | Second set of 1000 environments.                        |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| `MetaDrive-training2-v0`  | [7000, 8000)      | 1000           | Thirds set of 1000 environments.                        |
+-------------------------+-------------------+----------------+---------------------------------------------------------+
| ...                     |                   |                | *More map set can be added in response to the requests* |
+-------------------------+-------------------+----------------+---------------------------------------------------------+

